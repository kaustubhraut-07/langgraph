{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'What is the sentiment of the following review - The software too good'\n",
    "structured_model.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "def positive_response(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000023D8FF52BF0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 3.520371323s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 1.388459975s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 57.260668782s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 49.102966018s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 32.456720085s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 55.53606118s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 55\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m intial_state\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIâ€™ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m }\n\u001b[1;32m----> 4\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3050\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3047\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3048\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3050\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3051\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3052\u001b[0m     config,\n\u001b[0;32m   3053\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3054\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3056\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3057\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3058\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3059\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3060\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3061\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3062\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3063\u001b[0m ):\n\u001b[0;32m   3064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3065\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2633\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2632\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2634\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2635\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2636\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2637\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2638\u001b[0m ):\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2641\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2643\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mfind_sentiment\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_sentiment\u001b[39m(state: ReviewState):\n\u001b[0;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor the following review find out the sentiment \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msentiment\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m: sentiment}\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3127\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3127\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3129\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5527\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5529\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5533\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5535\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5536\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5537\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5538\u001b[0m     )\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1962\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1959\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1960\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 1962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:382\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    376\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    377\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    380\u001b[0m         cast(\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 382\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    383\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    384\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    385\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    386\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    387\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    388\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    389\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    390\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    391\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    392\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    393\u001b[0m     )\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1101\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1099\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1100\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:911\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    910\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 911\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    912\u001b[0m                 m,\n\u001b[0;32m    913\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    914\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    915\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    916\u001b[0m             )\n\u001b[0;32m    917\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    919\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1205\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1205\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1206\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1207\u001b[0m     )\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:2099\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   2098\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries\n\u001b[1;32m-> 2099\u001b[0m response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m   2100\u001b[0m     request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2102\u001b[0m     generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m   2103\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m   2104\u001b[0m )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:232\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    225\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    226\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (request \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:202\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mmessage:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:869\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    210\u001b[0m         error_list,\n\u001b[0;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    212\u001b[0m         original_timeout,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 55.53606118s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 55\n}\n]"
     ]
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"Iâ€™ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
