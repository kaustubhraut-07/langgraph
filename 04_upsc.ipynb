{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateEssay(TypedDict):\n",
    "    essay: str\n",
    "    launage_feedback: str\n",
    "    analysis_feedback: str\n",
    "    spelling_feedback: str\n",
    "    clarity_feedback: str\n",
    "    overall_feedback: str\n",
    "    score: int\n",
    "    avg_score: float\n",
    "    final_summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evalutation_score(state : EvaluateEssay) -> float:\n",
    "#     output = model.invoke(\n",
    "#         \"Evaluate the following essay on a scale of 1 to 10 based on the provided feedbacks. Return only the numeric score.\\n\\n\"\n",
    "#         f\"Essay: {state['essay']}\\n\"\n",
    "#     )\n",
    "#     return {'evalutation_score': output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launguage_feedback(state : EvaluateEssay) -> str:\n",
    "    output = model.invoke(\n",
    "    \n",
    "        \"Provide feedback on the language used in the following essay. Focus on grammar, vocabulary, and sentence structure.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    ")\n",
    "    return {'launage_feedback': output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyatical_feedback(state : EvaluateEssay) -> str:\n",
    "    output = model.invoke(\n",
    "        \"Provide detailed analytical feedback on the following essay focusing on structure, argument strength, and coherence.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "    )\n",
    "    return {'analysis_feedback': output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_feedback(state : EvaluateEssay) -> str:\n",
    "    output = model.invoke(\n",
    "        \"Identify and correct any spelling mistakes in the following essay. Provide a list of corrections.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "    )\n",
    "    return {'spelling_feedback': output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarity_feedback(state : EvaluateEssay) -> str:\n",
    "    output = model.invoke(\n",
    "        \"Provide clarity feedback on the following essay, focusing on grammar, punctuation, and readability.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "    )\n",
    "    return {'clarity_feedback': output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_feedback(state : EvaluateEssay) -> str:\n",
    "    output = model.invoke(\n",
    "        \"Provide overall feedback on the following essay, summarizing its strengths and areas for improvement.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "    )\n",
    "    return {'overall_feedback': output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(state : EvaluateEssay) -> float:\n",
    "    output = model.invoke(\n",
    "        \"Evaluate the following essay on a scale of 1 to 10 based on the provided feedbacks. Return only the numeric average score.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "    )\n",
    "    return {'avg_score': float(output.strip())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_summary(state : EvaluateEssay) -> str:\n",
    "    prompt = (\n",
    "        \"Provide a final summary for the following essay, incorporating all feedback provided.\\n\\n\"\n",
    "        f\"Essay: {state['essay']}\\n\"\n",
    "        f\"Essay Language Feedback: {state['launage_feedback']}\\n\"\n",
    "        f\"Essay Analysis Feedback: {state['analysis_feedback']}\\n\"\n",
    "        f\"Essay Spelling Feedback: {state['spelling_feedback']}\\n\"\n",
    "        f\"Essay Clarity Feedback: {state['clarity_feedback']}\\n\"\n",
    "        f\"Essay Overall Feedback: {state['overall_feedback']}\\n\"\n",
    "    )\n",
    "    output = model.invoke(prompt)\n",
    "    state['final_summary'] = output\n",
    "    \n",
    "\n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': state['avg_score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(EvaluateEssay)\n",
    "\n",
    "# graph.add_node('evalutation_score', evalutation_score)\n",
    "graph.add_node('analyatical_feedback', analyatical_feedback)\n",
    "graph.add_node('spelling_feedback', spelling_feedback)\n",
    "graph.add_node('clarity_feedback', clarity_feedback)\n",
    "graph.add_node('avg_score', avg_score)\n",
    "graph.add_node('final_summary', final_summary)\n",
    "\n",
    "# graph.add_edge(START, 'evalutation_score')\n",
    "graph.add_edge(START, 'analyatical_feedback')\n",
    "graph.add_edge(START, 'spelling_feedback')\n",
    "graph.add_edge(START, 'clarity_feedback')\n",
    "\n",
    "# graph.add_edge('evalutation_score', final_summary)\n",
    "graph.add_edge('analyatical_feedback', 'final_summary')\n",
    "graph.add_edge('spelling_feedback', 'final_summary')\n",
    "graph.add_edge('clarity_feedback', 'final_summary')\n",
    "graph.add_edge('avg_score', 'final_summary')\n",
    "# graph.add_edge(final_summary, END)\n",
    "graph.add_edge('final_summary', END)\n",
    "\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFrCAIAAABzCTuYAAAQAElEQVR4nOzdBXwT5xsH8PeS1BVa3Ft0+HCX4s7QIWU4gzF0w33I0DE22J/BsA1dGbIxYAOGDRgOxUtxKNICdUvu/yQH17SNtk1zaX5f+PST3F0ul8uT93nlRMHzPAMAALBLCgYAAGCvkAUBAMB+IQsCAID9QhYEAAD7hSwIAAD2C1kQAADsF7IggG4Hf34WHpaQGJcyhZMzXsk4jhPOL+I4JpxnJJNzvIppn3QkU3Cq5JSnnIxexFRKXnzKq3jGMaaZIK5QxpiK/so4lSplSVpKfEqzhLcR34pmqxd4/5QWoIdpXkKPxb/q14orV6/s/Uaol2SauUz7oxGFI+fowirV9y7zoReTvPBnccd3hcdFKxPjDZ0DJldwymS9C2h/fN0LaPaaXCFTJqsMLMPJOfFL1/Uu6u9d4cAlJ/GG30ruIFMmqZjBhQy/l8jJmTm6yeu0zVWgmDsDDQ7nCwKk8fBW9N4fw5xdZY7OVPpw4nTKEyrKdozXpJ4UmtzEtH9IMjnlvJSn6lzFqV8rPtWkMiasRusprykbU36VnGaK+BulN1KvI81PNiWRaQpWpuK0XiKsXPzLtDNomjVpPhXPa22SBhXTScrkuLcq91zywCklmITt++npvWuxrh5yRydZUqKhJdN8QTqI+0vPbHUVxWDioS9RTgvoT17vUqmcUxrIXpogMbKMZjlNRYcZJXfklYl8bLSySBnX9oMKMkAWBEjj1vk3h7a8ahaYt0AxTwZati8LcfVw+HhcMSZJf254+uBmbO+JJRmY4Jf5IYX8ndsPLszsnowBgBZKgR0+L4QUmF73MSUTY5K3f3OfSc+JPc8fIQWao/ekkk/vxh/e/ozZPWRBgBS7f3js7C738nJhoMuHLXzDnyQz6bl1LqaAvysDcxQt53H3Siyze8iCAClev0j0yIVDxvQqXs6LhlDCHsQxiUmMUxX/wI2BOfwquSYlYEQMWRBAS2IcUyZzDPRTJrO4KCWTmOQkJpPLGZjD1d1JJcWGfXZDtRcAAOwXsiAAANgvZEEAsHkcM3h2H4B+yIIAYAZKNjImuYSjfT0dMBkqDmrIggBgBko2KoaEkxPwyIIayIIAKWQyTiZHEW+DOI5DmW4m4Xp8gCwIkEKl4lVKFKY2CP2hkFHIggBgBk6qB6Lw6Kc1H64jzZAFAcAsPA5EyUE4HFmLLAgA5uEYRuAgJ0EWBEjBydT38ANDePQ95hT4GjWQBQFS8KqU+7aDbrwUxwU19zFG/cVM6pspM0AWBABzyNT3s5caGqnEgR7mwxmDarinBICEzJo9cd+fu5mZ7t2727NXO5Y91NkG+QZyDmRBAAm5des6M9+t2xl5FQAw9IgCWMXpMye3bdt489a13Ll9K1SoPGTQSB8f3yYB1WnWosVzVv2wbO/uf6Kjo3f8+vN/Z0/dv3/XJ7dv3bqNBvT/1NnZmZbp2DkgsM+gYycOX7lysUf3vtu2b6KJ9PLhn47p1rU3AxPs/G3b6dPHb9wIdnRyqlzpw4EDRxQqWPjsudNfTvhsxfK19KUIi924eW34iH7z5y2vXavenr1B27dvioyKrF27/sD+w6n9PXXK3ICmLQ28S1R01Lr1P5w5feL1m4gypT9o1qx12zadhFmnTh1fvuLrly9flPQv3alT99atOgjTT548umHj6gcP73l5eZcsWWbUyAn58uWn6TNmfimXy/PlK7B128ZZMxc2bND02rUrtOTNm9e8vHPVqd2gX+AQNzfcathsaAsCaJFlxzEWt+/cnDR5VNWqNdb/9OvnI7+8e/f21wtn0vT9+07S3y/GT6MUyNTF9NbNW9ZTkps395uhQ0f9c/QvKvKENTg4OPy+7zcqIhct/H7QwBE9ewRSQXnk0LlsSIGcVK/BzHFmlGZXr15a8d2i8uUrz569eOKEWa9fR8ydN5Wmf1i1hoe7x7Hjh8UlT5w4QlNqVK9N6XDZN/MbNWq2acPOxg2bzf5qElNfcs/Imy5cOOv6tSujR0+i77pcuQq0BkpdTJMCp80YP3DAiAXzv61fv8nCRbP/PrSfpp87f2b6zC9atGi7feu+GdMWPH/+7JtvFwiroi899F4I/Z87Z2mlilUfP3k0/svh8Qnx361YN2fW4tDQO2PGDklONuO2uepRQfRtoy0IkIoqO46xCL56iZp0fXoPoDKUslfZMh9Q0ZZ+se7d+jRqGFCsWIl3rwq+/N/Zf4cO+ZxpTnb29PQaOWI8y3aa3SPJa8fwZlwV84MPKq5bu71w4aIKhboMTE5Kmjx1zNvIt16eXk2atDh2/BC1qoUlKSMGBLSiRtjBg7/nzu3T/5Nh9JK6dRvevnPj+vWrRt/o8pULVEehJEqPhwweSUnUy9ObHlMDkRpzzZu1psc0NyYmOjY2hh7/tG4VTe/apRc9prbg8E/Hjv9i+M1b1ylI6EsPC3v6w8pNQn/Art07HBQOlP9oMXo6fty0j3u3P3Hyn8aNmjHTcDg6RgNZECAFJzOrRZFBFSpWiY+PnzRldPVqterUaVi4UJGqVaqnX4zq/mfPnVrw9YyQu7eFOn6uXLnFudS9xqxEikfHmHkuP2W1p08ff79yyY2bwTExMcLEN68jKAs2btycej6pvV66VNl79+4+fvxwwhczaC7VVKgxJ2RN0rBBwIaNPxp9o4oVq2zf8fPbt2+o07VGjTplSpdj6svVqu6G3mmmSYGCYUNHCQ+oSUdVH3G68C1TnydlQXpQrGgJIQWSa9culy1bXkiBJH/+AgULFr5y9aLpWRAE6BEFSMGrzGpRZBAVr9QP5uuTZ/WPK/oGdqbKPrXz0i9GczdsWN22beefN+6i3s7evfprz3V0dGRWIc3riJp5Lj+NvU2ZNrZMmQ++Wfrj4b/PLvz6O3FWlcrVqLZx7Nghenz8xJE8efIKY4TR0VEuLq7iYmL6MWzClzOpYUe1GXq7j7o0p6YeVWioDkSJ0MnJOc3CNBKckJCgPd3VVf2OQjOR0BCm1sJRNIpJg8Hif8rrryPCGZgJbUGANLKjoVOrZl36T91r58+fCdq5ZfKU0TuD/kq1ETy/9/cgKkDbte0sTKFSj0lBjriOKI2qUiuNhlSFp9r7ljoeqVOUuhZpLg0KNm/WRphOyYk6TsXFwiNemfJGnh6e1PVNNRiq6FBO3fTzWnd3jy4ffUyd4dQLmmZhoZ0XHx8nTonR5D+f3L7p15zbx5c+AoWQ9kShuxXMgrYgQGqWb+hcunT+zH//0gNf3zwtW7YbMXxcVHRU2PNn2sskJSXFxcX5+uYVniYmJv576hiTAM09JSRXbqivHWPOte8iI9/meb9vyXGtw2FI08YtHjy4d/r0iTsht8QsWKhQkXv374rLnDz5DzOGBhp3/raNWn6UWSlj0VgjdX1TXyv1x1Iz9GrwJXHJH9d89/3KpdTdSl2mwuEzAuGxn3+p9Cv39yv14kUYdbTSOoX/ubxzFy1anJmOl0nvm7QC7AOA1LLh6Jhrl2fO+nLv7zvfvHl9/Ubwzt+2UjrMn6+Ak5MT9b+dO3f64qVz1FagEu3P/XuePH1Mo0oLF8+uWKFKVFSkOIilrXDhouHhr06c+OfRowfMwjT3lJDc3VnVZ/Kbc+27kv6lz2r2M/VP7vj1F2GiWBEpX75S3rz51q3/wc+vZPHifsLEenUbUWrcvGU9NdPptVevXjL6Lgq5YsPG1TNnT6CGYERE+MGDf9wJuUnfI83q2L7r2bOntm3fRNuwe8+vW7ZuKFHCn6Z37tSDmqFBQVsioyJp1spVSz+sWqNUyTLpV961a2/qVv1u5RLKsvS9/2/1twMG9dB5mJVenEp636QVIAsCZLfu3fq0bdP5u+8Xd+7SfMzYIa6ubsuWrhYOu+jda8CFi2enTR8XFx83bco8ZyfnT/p37RPYqdqHNQcN+oyedu7S7FnY0zQrrF2rPpWt02aMP3T4AAMTDBgwnHqkp04b26JVnefPwyZOmFW2zAcTJ30unK5AGjdqTo22pk1SzgVs2KBp507dKavRt/bbrm30dTDNEUwG3sXNzW32zEWvXr0YOWpgl24tt27fOGzo6PbtPqJZ1AcwdMjnm35eM3bcMPo7ZPDINq070vQWLdoOHDB8245NHTs1/XrhzEoVq06fNl/nyqmvde2abS7OLkM/7RP4SZdLl89/MX4aDTkzMBOHi+8BiFZPCvX0dWw7qDADPdbPCGk3KH+JCu5MSlaMDmn6cf6iZS24VdRqvH8/tGTJ0sJT4Wz6H/+3WZxic968SNy98uFny0oy+4a2IEAKuZyTy/GjAB1oGG/w0F7Lv/06LOzZ9etXly9fQB2n/rpG7MC24BhRgBRKJa9UmjFU0r5DY53TExMTqa9M53VoihX3++7bn5hl0KjVli3rdc5ydXOPTXdQYgY2Sf2RJHimBKe+jguzpKpVqo8bO4VGagcM6u7u7lG9Wu1hw0bTVzxpyuhgPWOEbdp0+nTYaCZVKhWOjlFDFgTIuNWrN+ucHhMT7eamu3dOIbfgj659+y5NmrTQOSshPt7J2ZllepPUtxeU4CgKry7UmYW1a9tZPHFFNH7s1MSkRJ3Lu2qdXyhBMhmOjlFDFgTIuAL5CzIp8XD3oP/MwnBnJW0+Pr4MbBmyIEAKmfpq2ri0okGcFDtEATIMWRDsHc/zl98rqhzgntuBgQE8+/ffUwmKomXKlGHSwTEeydlMHK6lrYEsCPYoIiJCzHxXr16trNGxY8ebf7owMCbi9etZs9Y9fvz4w/cqVKjArItXn/XFwBzo2RYgC4K9uHv3rpj5YmJihMw3ZsyYSpUqicvc2h/KwCBOxtq1bffZl91pH17QWLx48c2bN6tVq1a1alUhKbJsJ81LfEscdpgAWRByrKSkpMta8uXLR2mvRo0agwYNKlKkCIMM4VXv7uTn5ubWQINpdvX58+cvXry4atUq+iukQ+Fv9tz7Ikdc4ju7YYcJkAUhR3nx4gUlvEuXLtHfkJAQocHXo0ePefPmubsbv7AIj0M/MsTBwaG2hvBUaCNu2rSJmto0fCi2ESlxMgvhMMplNh5XTdFAFgSbd+vWLSHzXblyRalUUtqrUqVKu3btypUrZ+aa1GfCoUmRedr9osHBwZQRg4KCpkyZUrhwYaGNSN2n3t5Zeg8gHqNcZuMYzhZUQxYE2xMfHy82+EixYsUo8zVq1GjkyJEFChRgICUVNAIDA5mmvkL9pQcOHJg/fz5lQfHgmrx58zIAK0EWBNvw7NkzcYTvwYMHQoOvX79+9MBZzyVRQGrKaPTs2ZMe37t3j9qIJ06cWL58OY0dir2m1F5kANkIWRCk6/r169TJKbT55HK5MMjXqVMny52p5ujC5Dhd0CCFgjm5ZEG5UUKjS5cu9Pjx48fURqSkuHbt2sTERLHXlBYwcW20VejdM1dSkkouZ4AsCBISHR0tpj1SqlSpSpUqBQQEjB07Nns6zdy8HGIjkxjo8fJpHA2++kTZNgAAEABJREFUFfTP4sZ3YY327dszzfFNlA4pKW7duvXNmzdiG9Fw1UfhxIWFRBcvK637PUnc/etRMtT5kAXB6qgdIHZ1hoWFUdqjrs7BgwdTs8/wLUwtoXH3XDuWhDHQ48wfLzxyW/bAQqrutNKgx5QFhcNN9+7da/gk/YKlXB7ciqndjoHpQq9GFijuxOwe7rILVhAcHCwe3uLi4lL5vZIlrX/Dz4O/PA29HNt7ir3fejS9v35+HPEscdBXfswaYmJiqIEonJV48+bND7UIC2yaez85Wdl1tD8DEwQtD5XJuMCppvY552DIgpAdIiMjxbRHfZ7lypUTDm+hvz4+Pkxizh+J+G9fhIePg2duOePe9Zdw3PuTKDgm47Ru48MJdxsSTkLmOY4TF9Oa/n6K+nqXvGZN6idUDKlUPNNaSmuK+qyNVC9PQz2fS1lA++3oLWSazdA8FVYl4ziVehL/7poh72a9Xz0nlAXvT7lL+bRMIWcxUQlvXyapVNyQeZLIMUlJSRfeo6RIgSRcuebe8fyREcm58jq5eitUyXpOH9T6aO92ctrJqcjU07X2jJ6Fufd7UPdi778djqV/oXaA0PukuhJcqjfimJzjlCrewMfS+Sm0JzooVFFvlK9fJLh7O/SeUIwBsiBYzoMHD8TT+MLDw8W0R32ecskPyj+8Ff3vnvCYyOSE+HdT1JlP81vhNFlQvBevUMQIOUZzSWeZJtm8W16TFFPKWSryVFpFlVzOKZW89sq1pvAqdUqldMsLJez7LCoWmuop795FTIXvEyynNV1YlfgW7z8Ox2v9+NVPGS8Uo0LiVL1/H0dHTubAFy7p0qKPtG4jJRLbiJQUG1ToX8irupPcTaVU6DyNXns/aH8772sJaQlXUUgzJ/3CMvUXJEs38d17icvrSJ9aU8QI0flGMnXkMZUyZXaqDKr5LOmrXmk+pqMz5+jE+VVyrd8hHwMNZEHISuKBLcTLy0vIfJT2TD/YD9IYOHDgyJEjaTcyMIFwkr7QRixYsKB4ddNcuXIxAF2QBSFTXr9+LaY9avNV1pLFFwexV/369fviiy+sf9MGG3T79m2x41Q8SZ+SYr58aAZBCmRBMFtoaKh4PkNUVJR25mOQ1Xr37j1t2rSyZcsyyIT79++LvaYODg44SR9EyIJgXHJyMqU98fCWPHnyCOczUNorWrQoA0vq0aPH3LlzpXD0bI4hnqRPfxMSEsTbX/j5WefwV7AuZEHQ7dWrV2JX582bNyntiYe3eHh4MMguH3300bJly4oVw+F8FiGepE9/qXtfvCcUGt/2A1kQUoSEhIhHdcbHx4v9nBiUsqIOHTqsWrWqUKFCDCxMPEmfkuKjR4/ENmLFihUZ5FzIgnYtMTFR+z60BQoUEI/qxHiJRLRp02bdunU4oCObCSfpC0lR50n6kGMgC9qd58+fi2nv7t272se2WPAmqJBRLVq02LJliwSvLWA/hJP0xbMSqZooZkRHR0cGNg5Z0C5QZVY8qpO+cTHtZeA+tJDNmjRpsnv3bk9PTwbSILYRSenSpYXbX9Bfd3dcy9smIQvmTHFxcdo3ZyhevLh4VGf+/PkZ2I4GDRocOHDA1dWVgfQEBweLbcSCBQuKbUScpG9DkAVzDuE+tELmo7F9Me3hPrQ2rU6dOkePHkXPm/SlOUlfbCNiTFfikAVt2/Xr18XMp1AoxJMZqKOGQY5Qo0aNM2fOyGSWvZ8RZK379++LGZF+mGIbEQedSRCyoI2Jjo7WPqqzVKlSYubLkycPg5xFpVLVqlXr7NmzDGzWkydPxF7T+Ph48dKmOElfIpAFbYBwH1rhNL6wsDChk1M4nyH770ML2SkhIaFJkyb//vsvgxzh5cuX4oXcIiIixEub4iR9K0IWlKirV6+KDT7hPrRC2sOVtOxKTExM69atjx07xiDH0T5J/+HDh2IbESfpZzNkQal4+/atdldn+fLlxfMZcK6Y3aKo6Ny58+HDhxnkaLGxseI4oniSvpAUOY5jYEnIgtZEQ+ji+QyvX7/WPoEdR0MACQ8P//jjjw8ePMjAbiQnJ4u9pgQn6VsasmC2or2t3eDz9vYWz2coXrw4A0iNhoEHDhz4xx9/MLBX4u0vKDUKJ+kLGREn6WcVZEGLE+5DKzT4aLQP96EF0z1+/HjEiBG7d+9mAO9P0hfaiMJJ+sJZiThJPzOQBS0iNDRUzHzR0dHiyQzU8mMAJqM+83HjxgUFBTGA1IST9IU2onCSvtBGxEn65kIWzBrUlS90cgrnM+TJk0fMfEWKFGEAGRISEjJlypRt27YxAP3Sn6QvtBFxkr4pkAUzTrgPrZD2bt68qX0aH+5DC1mC4mrOnDm//PILAzCNcJK+kBHj4uLEI2v8/f0Z6KJgYI47d+6Ix7YkJCQIaa9ly5a4Dy1YAvUxUNWeAZiskEa7du2YpqYupMMdO3aEh4eLlzbFSfra0BY07u3btxRDwiAfhZd4bAtu/w2WRlG3YsWKtWvXMoDMefPmjXght0ePHgkNxF69eqGahWqmcTNmzKBxvt69ey9cuBA3uIFshsvDQpbw9vZuosE01ySiBuKuXbuioqJGjBjB7BuyoHEUMYGBgVRvYgDZSyaTPX/+nAFkKTc3twYNGrx+/ZrahczuIQsaRz0GNDzDALIdYg8sB9ElQBY0DrEC1oLYA8tBdAmQBY2Ty+VKpZIBZDuUU2A5iC4BsqBxiBWwFsQeWA6iS4AsaBxiBawFsQeWg+gSIAsah1gBa0HsgeUgugTIgsYhVsBaEHtgOYguAbKgcYgVsBbEHlgOokuALGgcjhEFa0E5BZaD6BIgCxqHWAFrQeyB5SC6BMiCxiFWwFoQe2A5iC6BjIExiBWwFplM/QtVqVQMIKuhZBMgCxqHWAErQviBhSC0BMiCxjk4OCQlJTEAa0BRBRaC0BIgCxqHY0TBilBUgYUgtAQ4OsY4xApYEcIPLAShJeB4nmegS9u2bcPCwmj/cBwnTFGpVIULF967dy8DsLDKlStTJ4TwWAhCCr9u3bpNmTKFAWTC9OnTqRCj6KK4oqASyjd6evbsWWaX0COqV+/evZ2cnGQyGfceTQwICGAAlle2bFnZe1RC0d+iRYv269ePAWTOiBEj/Pz86AGVaUJokSJFijB7hSyo18cff1yoUCHtKVQMdenShQFYXs+ePd3c3LSn1KlTh7oiGEDm5MuXr2nTpml6ATt27MjsFbKgXlRREpqD4pQaNWrYc40JslPnzp2LFSsmPqWSq3v37gwgK1DJRnV68SlV9zt16sTsFbKgIRQZYkmUN2/eXr16MYDsQkWVi4uL8LhSpUr+/v4MICt4e3u3adNGGOWhRmHLli29vLyYvUIWNIJGYlxdXelB1apVhc50gOxBZVOpUqXogY+PT58+fRhA1qGIEpqDBQsW7NatG7Njxo8RfXg75s6FqIR4w0sxmYwZvcyTSctwTMVnagHNMpzK4OeiOpDhz61ZgJZQ15XOnv0vNi6uSuUq2tUldS1KvQSnfxt4Fc8ZWD9jhrZBzvFKzct1bqqBnaC95Tq2ivEqfdus/jQ6ZskVfK48DjVb+jIbcXLvi6jXSpWKM/0lChlLNuciZbSfNAdtmnp8tSZamOlHYwtfOsXA85fhwcHBXt5eVatUNeklMk6pMv19zP4gKa9izMwXqTk6shIVXf0rejJb8ORB9M3T0UlxaX8ywq9Ps791/ELF32ZKKaT59jnNkb46f7lyGVPqCj/N69KuX3iqPTFdEZHq56+eK0xL5+Gjh3du3S5UpHDZMmXTvEp87bs16nq5es0qTUuK1zXr/S7Suf2Mvdsh4nSZnKmUulZi4OOn3uT0RaXCUVWsrFuZD400c41kwbXTQxJimYOTLCnBSMjLZMZ/S3KFTGmssNG5nlQfj3Z6ptMtp8kGBhdQRyv//t1pk7jUGYK2k+cN7TzDO8RoFhS3UOemGth+TrN/eL1bpXvPGNgeByd1dKqUfNWm3rVbSzoX/vHTkwfX4xQKdSGdbM7Vfkypn2lTpwH6fpUmZ0GZJmuYnJiFgJfJ1W+hfa6OwbdQh4RcwSmTzcuC9NnNvSaE5ohpPgMXN1U48cmJzNGZGzRH6r2762eFxkarHBw5TdGXav9zmhqumM/SVHHE36ZYAqTKWJrXpnkv4YtOM1H8SepOA1olQNp1cqnSUqqfNkcbmuqzUHRpirI0L9J6rVCt1pkF6QPyKpk6iaSd9e6za94u7fbrKbvSh+672kbqT/fup6FZf5pt1pUFeWUSUziwPtOKurg4Mj0MZcH/TQzxLaRoEVicgd27dyPi5M6I+p18KtbNxSTp5O8vrx5/23ZwIe88Lgwk7MiOR09vJwxbWJJJ1Y9TQtxzO7YbVJSB7TvzZ9id89GfzCjq4q47EerNghQHhUs51++MI7MhxS9zQ+p1zFWxng+TmL82P31wPbbHF9ItWEHbuUPPb5+NGjpfit/XmmkhPgUcmvUuxiCnCL0R8W9QxKeLdMeb7qNjTv3+gjrBkAIhjfwlnP478IZJT+iV2JI1bWO0CUj1gHz0959fnzGJCT4dkZzAkAJzGL9yuR1duD0/PtI5V3cWfHgn3tkDlxiFtPw/9EyIM/+gCAuLexuXnMyqNcrLwHa4eTs+u5fIJCbkYqyTm5xBjuOVxynime6LpurOgkmxKmb+0DfkeN65XVTSu/pudLScxz0/bI1cxsXHSK6USYhVKZWSq+dB5ikcZYlxembpnKpUMd6cA80BrEiOursNUh94KL1CRn3gqxJFXw6kSuZUes5QQLcnAFgBr65qo9UF1ocsCGaQaiXZ2EUQQII0J+wzAGvTlwU5hlIF0pFqUOi+6g1ImeaMbAaQPRQyTu6g74pauvEIUACwHPWwIFrwkF2SVbwySXe8oUcUcgBU2WwPp76opuS+OHXfOqLJzujOgurr2jGA9KRaQqBRYWukeXSMum8dsWRndPeIqq/hizQIOkizhEAHPgAYIpMxTs8pVXragjIOPfaQnuYq8QBZAceIQjZSt+v0NO10Z0GVikfvOKTHMYQFZBGe8dKra8uQm3MoXv+d7PQfHYPGIOiAAgKyhlzGyeSSCyfevNshQ06gPwuiQgQ6SLOAQD+t7VGqeJX0rtj57g7mkOPIOOFm17pm6Z4q46zbLRAaGtIkoPrVq5dYpgXt3BrQvCbLqE4fNdu4aY3RxWiZrt1btWhVh2WR/gO7f7N8AXu/K65cuciyQib3hlRlWT8t7Z9mLWoxM82Y+eW48Z+yrEBf94SJI5u3rP3L5nUsKxz55y+KnzdvXrMs3U7SsXOAKT8NvXDWfDra5Z52KGZ2V+sXGxs7b8H0tu0bfjnhM5YVKNLoI1DUsayOt8yvTV+46c6CNCho0x2i9+7d7dmrnfD4g3IV+vYZxCwpISFh3fofqlevvXDBdwzsT8OGAc2btxEez5o9cd+fu1lGHTq8/8rVi7NmLAxo2orlbGh1maxH94agcrYAABAASURBVL6VKlZlFnA1+NJff+3r/8mwIYM/Zzmailcf76Jzlu4eUc15EjZcT7t1+7r4uFy5CvSfWVJcXCz9rVWzXpUq1RjYn4CmLcXHt25dr1Ej410CMTHR+fMXrFu3IQN4r9fHnzDLiI2Nob/NAlp7e+di9irLrh1Dza89e3+9cPFsWNjT4sX82rTp1LFDV2EWdSpSXePt2zcbNq52cXGpUb3OZyPG+/j40qxTp44fPnKAKr+RkW/Lla3Qt++gqlWqa6+W2lg7fv1lz64jCsW7TQ0K2vLD6uVBvx6kwfUdv/7839lT9+/f9cntW7duowH9P3V2dqaXCL0H1DAf/ukYmUy+ctXSQ3/9J7yc3nH5iq9fvnxR0r90p07dW7fqwNQ3qIvWuSpTPvjZc6eFzoTZcybNXzD94P5TycnJa39aefrMiRcvwipUqNK5Y/fatesLC0dEhNPGBF+7HB8fT2VlYJ9BRYq8u6v1/fuhC76e8eDhvSpVqgema7wmJCasXLXs6LG/eZ5v2qTl4EGfyTX3E9r527bTp4/fuBHs6ORUudKHAweOKFSwsPCShw/vL1k2l7pSCxYo1KBBU/pEjo6O2utUKpXU+Rb2/NnPG39jpso5fVhG94+BkKYeKvqOjp04TC/fvevwkiVfRUdHLVm8ikKO5i5aPGfVD8s+6txTX+h6enjq3KSRowYGB19mmtAdNHBE7179r127Qr+amzeveXnnqlO7Qb/AIW5ubsLCBmb98L/lB//6w9XFNSCgVeHCqW6bTiMd586f2bZtIwWhv3/pz0d+WbpUWWbwJ0BxQh+E3oupe1YqftJvaMWKVdJs+aVL57+YMGLE8HGdOnZjplGPuciY5JjfT0uBRGXOpcvn6bdZvnylnt0Dhf3TrkOjXh/3p1rRseOH6aupWLHq5ElzPNw9aJaBIkInircuH30c2HfQb7u2b/p5zTdLV8+Y9SWVGH5+Jbt17d2qZXthsT17g7Zv3xQZFUlrG9h/OPWHTZ0yV7uKlsaatd8LHe+duzSvQV1ZX39noIAyEG+HDh9Yt24VvS/V3np066v9FhmIN6anlNYWHv5q2PC+FI2zZi5kplFfDYEz7zqiZl9N+/uVS86ePTXq8wkL5n9L5cXyb78+feakMMvBwYH2gkwm2/XboQ3rgqgNvn7D/2g67ei586dSd+LECbPmzf2maNHiU6aOoa9Be7Xt23WJi4s7fuKIOOXo8UP16zWmcmTnb1s3b1lPfQX02qFDR/1z9C/hh0oZt2ePwHz58h85dI5CRHtttHOnzRg/cMAI2sj69ZssXDT770P7mTqX6F6VKSh6fgtSd4JPnzafUiA9+HbFwl+DNnfu1GPzL3sbNQygeD167BDTlCZjxg2lX8uY0ZN/WrMtl3fu4SP6PXn6mGYlJSVNmDQyT55863/6dejgz7du20hfs/a70DpLly5HO6p3rwHbtm8S+txo/GDFd4vKl688e/ZimvX6dcTceVOF5cPCnn02sn/FClWoaO7RI5D62WgNabZ84eLZt2/foNBnZpBmH5bM3O0yZf8YDunf9/1WsmSZRQu/p2QjvmT/PvUCX4yftnf3PwZCV99WrVi+lhJt8eJ+FLqUAh8/eTT+y+HxCfHfrVg3Z9bi0NA7Y8YOoQKUljQwa/eeX3fv2UGbvXLlxgIFCm3c9KP2W1A1a9fu7b169adQV6lUU6eNFU5XMPATWP3jit27d8yetXjq5LkUohSoVO6nWueDe1Onj+3QoavpKZBpriMqxVt5m9lPm5iYOHrsEKqSfr1gxZJFqxRyBRViVLIx9W0vFVR7aNfuo8N/n6WxEtpp9GsVXqWviDCKAo/qW/TyL8ZNo9U2atiMCrHnz8No1o2b15Z9M79Ro2abNuxs3LDZ7K8mMfURHoYqGlTTolKLHlAJRuWAgQLKQLzRWCYVOy1atPt5066WLdqJn1GQgXjTV0qL6Gf15cTPKHdOmfwVM4O+g2P0tgXNvkj/tGnzqXFdIH9Bekztuf379/x39t/ateoJcwsVKtKn9wD1I3cPagtS4UsPKfOvWb2VWodeXt70lNqC9AOmHElhIa7W1zcPpZnDhw80adycaaoAVPTP+2oZPe7erQ8tWaxYCWFJqkTTOw4dYqh3m6psDRs0bd6sNdNkL+p9EjoEMrAqfSipHzj4O/VgdGjfhZ62ad2R1kYlEa2ftlzd/li86sOqNWjWp8NGn/z3aFDQZqofUW3xxYvny5etoeRNs2hKtx6ttVdb7cOazQJaCfuW1n/kyMH27T764IOK69ZuL1y4qNDaSE5Kmjx1zNvIt16eXvQbc3J2pgoB/T7p7aiVQ3VS7RVSc5lWsnTxD9QSYjZPZW793ej+YQZDmmq4np5eI0eMN/AWBkLXRH///aeDwoEKHeEHMn7ctI97tz9x8p/GjZoZmEXlCxWOwo+IWgnUT/D48UNxnVRVGv35RNo2ehzYd/CkyaMuX75APfn6fgIUTtt3/Dx61ET6LDS9Vq16tE/CI15RnVVYkj4XlY/U0Bnx6VhmDk6mv1iyHU+ePKJdSg01oYkzY/qCy1cuCOmBUFNG2G/0U6X6DbW9KHtRMtBXRJjyjlRjpnYYrZAeU9ahMi0k5BaVGwcP/p47tw+FNJUG1Ca7fefG9etXmTkMFFAG4o2qXPny5qd2KtP8TKgZc/HSOXGd5sYb019KCyhVT5s+LjYmZtXKjWk6bwzj9FdvdGdB6mxTMjPx/M6dW8/8d/LRowfChAJaxSu1Y8THHh6e9MGEx/Tx1qz9jmofYtNHOJhNG1XDqa4hFO7/HP2bvoaaNesyTbXo7LlT1IsYcve2EHa5cuVm+lHw3Q2906xZSnYZNnSU8MDcVRlACZ6qh5TpxSlVKlf7c/8e2n5K8PRGQoQxTUlKs+g3wzS/JaoT5M9fQJhF3cV58+bTXq32Cqkf4MRJdQuDSvCnTx9Tk+XGzeCYmHeB8uZ1BO0oqqyVKlVW/v4u7FQaCt0mnAbVrSjU6BdboUJlZg6el0mwMZiBolTf/knFYEiXKf0BM0Zf6Jro2rXLZcuWF8odQuFRsGBhGj6gokffLCpZKJa0e5C0f3rE36+UUCSRCuXV3/7TZ4+pVNL3E7h/7y79pfcSXkIl7OxZ7yr7FEgJCfFUK6cKwYxpCww3O9KT5nVEOTPPmqf6PY2oLVg4s3mzNvRzph+U9pgO9RakLFmwCCUw+sHS6I++IoKZRvw6PDT9CtQ6pL+h90LKlasgdr83bBCwYeOPzBwGCigDoUjxVryEf/ptE5gbbwZKaaHsoh6sm7eurfp+o7kDmRRrvFlHxyiVzKzriNKmT5w8KikpkcaraFiL+r5phEN7AZ2BRQ35UWMGfVi15rQp86hqQ8s0b1k7/WLUieTm5n706N9UdTp2/FCL5m2Fwos6avbt20WtaYonqgpRPcvwsXnUTUHb6eSkY7TP3FUZIERkmo9PXkeE0yz6GQhDRyLhu6QfhotWxxpJs520B8THrq6uNMhKD06ePDp1+jjqOhs6ZJS/fynqfxcPd6Z6hs4ooe4IqkxR8NFjZyeTBj61cZxKgrX3DBSl+vaPyGhIm1IP1Re6JqKAuXnrepqAea0ZMtA3iypD9P1qx5Kzs4v2MmkCiWlij+n/CQjxrDNUKJaomUhFGP14zaqVS5m54U0ffPmyH//Yt4t6F2ioj3LDJ4FDxAOGtX/Fzi7qL4ICz0ARwUyjszil1ebNm198KmYs0xkooAyEIsUPdUeJE10yF28GSmmKN6GdTT9GJ/PLLgOy5uiY23du0qjp4kUrqeNOmEJ7LY9vXsOvor5gqhPRgJaLJj7StwLfbaJCQXXbv/7eR/XcK1cujho5gWn2yN7fg7p26dWubWfxHQ2/nZOTE1VXxWaoKAOrMsBHU/EZN3YKVRK1p1OAUguPPunc1H1icpm6WKTatHCgqUi7E4CpgyNOfBwTGyOEOA1N0Tg8de6n32wKvpjUa9BGm0fxRBVY6lDNcKvXphnePyyjIZ2GztA1XW4fX/p+qY9Le6KXp7eBWW5ubpRoqYkmTkwTV3FagRSt+S1Q7Bn4CQilWKyefUXt6SGDRk6c/Dl16H3SbygzhzR7RDNw7RjqHKbOQ/ouLlz4j5p08xZML1bcT+gg1S5t4uPUe54qJQoHB6aniAgLe8oyihIDjYmIT6nXmpnJQAFlIBQpfuK14i1NqJgbb/pKaQFF48zpXy9ZNpfq8dRza1arXXM0ljlHx2i6BZjphKaJWEbcvx9K/42+iioF1KIXUiAxMD7ctm1n6jimiifFlp9fSabpHKcxUt/370jZ9N9Tx5hBVDqUKfMBtfrFKT+u+e77lUszsCoDChcqSl8k03SRC/+LF/MrVrQE1YP8/UvTG1Gsi7Py5Ssg9Jnkz1eAKkE0ziysJCTk9qtXL7VXS4Wy+JhGsKh3hWl2oHa5fPz4YfExfVLqxBDHJw4dPjD+i+HUSmCaAXMqmqlEdnVxFY+msWky86/3Z2D/CDIW0umlD13TUW/SixdhlSt9KAZMLu/cwoCcvln0U6egunbtiriS02dOaK/z4cN7wrEbTBNITBOxBn4CFJ+Uy4VuMaapMlIT+cCB34WntWvVp96tYUNH0zCzuaNQTMVJ8GArc68dQ2OulPmY5igHGo2bOeNr2l3CcQ/k8uXz4pJ3Qm7RLMp8BooIlgm05nv374pPT578h5nJQAFlIBRpGRp7pgacsJJTp49rr9PceNNXSr/bQr9SFG+zZiykBcy+rATH6+uy19+Vb04o0LdIX/A2zUG6wqFQNKoZ9vyZ4Vf5+ZWi4cA9e4OoMDrz379Uk6ImDu3r9EsWLlSEeqiDdm6h0WBhCnVE0HdA8ffk6WMqsKizuGKFKlFRkcLwGLXQac0nTvwjjugIOrbvevbsKdpOGr/dvefXLVs3lCjhb3hV5qJQpkoxVY1pqJm+XUrt478cLlwFhloVNCy0ePEc6gqmN9q1e8ewT/vu1/yE6tZtRJuxeOlXFDGU/2Z/NYlqTNqrPXzkAO0ievDX339SzDVp0oJpxt7PnjtNn4V24I5ffxGWFHZ72zad6N2XLptH3aTHTxz5cc0KaqRqd8dR5WPmzIU0IksFNLNxKvOv92d0/2QspKl0y5Mn77n3XwrTFbqm69q1NxUu361cQlFBkfy/1d8OGNSDhn8Mz2rSuPmx44eFi3dQhKdJTtQWWbxkDn0o6nr5ZfNPNPxMdXwDPwF3d3ca8dq9ewfNpQ9F++H8+TNpTsDt1LFbrVr1Zs2ZaNZPhmc54fZttCcXLpq96odvHj95RF8EFc30vQsDYOTlqxf0w6TaFYXQ73/spJ8tRYiBIiIz6tVt9ODBvc1b1lNNhYqFDFx4y0ABZSDeGjduTrFEgUHvSxGya9d27XWaG29MTymtvU6qTdI4xfoN/9NuGxin0tvK13+mhDmXZqSO3SmTv7p+42rHTk0nTx1DfXQdOnSlwrrdU7d/AAAQAElEQVRf/64GXhXQtGXfPgMpGmg4UDgSiX5v9C1S2ZR+YapnUTAFBKRcUINGE2m44pP+XfsEdqLvb9Cgz+hp5y7NnoU9pSoq7dZpM8ZTHV97JS1bths65PNNP68ZO24Y/R0yeGSb1h0Nr4qZr2ePwC/GT9+8dX37jo2Xf/t1wQKFx4171+SaP/ebRo3UBzF3+kh9LB8NAn/0UU+aTmXNvLnfKJOT23Vo9MmArtRXIB49lZSs7uWgXbr6x2+pX57Ka1q/cPjDgAHDa9WsO3Xa2Bat6lDgUt9y2TIfTJz0+d+H9lM9YMH8by9dOvfFlyOowVerZr3P0h3QSK2TwL6DqarF7I/R/ZOxkCa9ew24cPHstOnjxL6g9KFrIk8Pz7VrttFAy9BP+wR+0oWqLF+MnyZ0tRmY1af3QMrxVCpRtFDFfLjm0E3h8HSKJSqgixYt0a17q249WtNWfTVnqdCtZOAnMOrzCTQyumTpXPrVUNk6e+Yi8QBREcUelf4LF81iJssZx4h+UK7C2DGT/z70Z9/AzvRFXL16cemSH4oX9xPmUo8ftcubtahFYUOtvZGffSFMN1BEZFjDBk07d+q+YePqzl2a/7ZrG32DTHPcn1kr0VdAGYg3qh0OGzrqv//+bdqsxtcLZ1IksMzFm75SWlv3bn2ocjlz5pem35aEZ3oPduF0rmXDnPu8iusyuhiTjElTRlP36eSJsxlYz5sXibtXPvxsmXk9e5YWEZa4+euH/WZKa6tECF2d9qx6GB+tHPhVCSYlWxY9jHmj7PFlFmyVeKo7yxZUC6FO+5IlSwtPb9y8NnxEvx//t1mcYuf++vnZi/uxwxb5p5+l++gYTjL3kYuOjr4TcvPixbPXgi//tHY7A6uSatVdituF0LVFBo6hkDgaKqPGE/VO9+geGBHx6tsVC8uXr+TvX4qBSM/Aib7riEpl3PrBg1D6ammsZdasReJ5J9mPqvPBevrZ27Tp9Omw0cw+SPXqx1LcLn2h275DY30vmTBhZv16jZl9kMkleX9B9RVtbPIi31WrVB83dgoNtg0Y1N3d3aN6tdrDho2mpI54Exio3ujOgjIZU0rjphJUnTly6ByztvFjpyYmJeqc5eqSqSO7IGtI7zgLfaG7evVmfS/J5W1HZ62olFK8v2AW2v2bSRdFy0I0DCmeeyBCvInMu3aM2ddPy+mEa3+DdKNCgtdl1kO4JBtA9kC8CXhzrx3DzD91FOwBYgJyNvVFumynRgVZQk9bUH3NNbQGAcBSOBnHSXJcMAecxQhm0TcuKFNJ8a4nAJBDUFWbz9HjgiAxvL6T4HVnQZVKxUvxsskAOnEoTQHAALmck8t1d3brmSrjctBNxSHHQ/c9ABiiVDJlsjlXUKO+cdSuwXYgCdoeGheUmXGbqWyDw+Ptjr6z5jkcIwq2A7Fqe2hcUGX2vbyzgTROlIZspO/OSjyq1wAAkOMZuIIa0iAAAORwurOgo4ucT5ZibwVYlzKZSXAsh1eqr/kHtkXhyDm4SK6q7ejEEl0QTDmQTMEcXc2517yLG4uPRxaEtJ7dj5LglTV8CjlSz8WbiDgGtiM2MtHZTXJZ0M1LkRifxCDHiX4T7+ise5buIq1Jd9+4aAwSQ1q3L0T7FHBk0uPuKT/zezgD20ElTN02PkxiWvUrmBjP4uISGeQs0RHKD2p765ylOwt6+bjkL+H4y/wQBvDe0V8fx0UmdR9TlElPv+klXtyPfxL6loEt2Px1iE9Bx8Kl3Zn0FCvvHLT0IYMcZPviEDdP+YdNdN9DgzNwx/rT+19ePPy2gJ9roVIuLq6mtAB44cwtXv8JXDpmcWkOdNf76pQFeUNniHHCkT28SZuqZw28yvBpQ4bXzxs5gc3YfP1vy+k6jvv9xhherbjJuhbjhdOkdH8mLvnF48QH1yOViWzQV/5MwlaOC/HwkRcv75Ern7Mph3fxmh+ACWeIGYwWzZfCqX9JqZZJsz+1V5F+dcI6dMaV5pK++mbp3qx3a0s7Me0K9L1cVzSkXzbtlPTbmX4zEuOSHt+NfXY39oM6ng065mVSde1MxLGgiLzFHIuV9XBylXPMyGA4fWKZ9m8zXVAZ/cnznPqf8FjnL1HPz9N4kavn/d5tofo701eU6X5LzVtpz0r1jeucLOyfdz8Q3YWYjvcQH/Mp13DRrFRHJHNMpuvcvsRE1bPQqKd3YguVdG0zQO+9NQxlQaZJhDdOR8fHKpWmdJWb8vmML2M8gxlfifEFDL+JCdtgmVdzcs7QxRUNr9nwp9b/QzG8VpkDp1DwufI7dPu8GJO8LYvuR4Ynq+8FaeJXkOEqyXvv9rrxco6l/i3rm6n7hTq/W0NpjGVCxl6f7lXpVyNTMGcXeZlqrvU65mPSdvl4+PlDbxLj+GTzO0f5DNyazpTCM+tkOEIyHlqZ/qFlgFzBHJxlRcu5tOhVwMBiRrIgkBMnTuzYsWP58uUMINsNHDhw5MiRVapUYQBZLSAgICgoyNvbm9kxBQNjkpOTFQrsKLAOhB9YDqKLIQuaAoECVoTwA8tBdDFkQVMgUMCKEH5gOYguhixoiqSkJAcHBwZgDSinwHKUSiWiC78u41AMgRUh/MBCKLTkcine3Sqb4ddlHIohsCKEH1gIQkuAXWAcYgWsCOEHFoLQEmAXGIdxQbAihB9YCEJLgCxoHGpMYEUIP7AQhJYAu8A4xApYEcIPLAShJcD9JI1DrIAVIfzAQhBaAmRB4xArYC08z6tUKhzODpaAkk2AXWAcxpDBWhB7YDmILgGyoHGoMYG1IPbAchBdAuwC4xArYC2IPbAcRJcAu8A4xApYC2IPLAfRJcAuMA6952AtiD2wHESXAFnQONSYwFoQe2A5iC4BdoFxiBWwFsQeWA6iS4BdYBxiBawFsQeWg+gSYBcYh1gBa0HsgeUgugTYBcZhDBmsBbEHloMsKMAuMC4hIQGxAlZB5RQDsAwq2TiOY3YPhbtxAQEBs2fPbt++fdu2bfPmzcsAssv27ds7dOjAALLC8+fP72h5+PDhsmXLmN3jeJ5nYMy9e/f+0ChatGi7du3atGmDCxyDRZ0/f378+PGjR4/u2LEjAzCfUqm8deuWdtpzdnYupcXPz48BsqC5zp079/vvv+/bt6958+bUNKxbty4DyGqLFi2iMmvx4sWenp4MwDQvX76ksLl9+7aQ8+7fv1+mTBnttOfl5cUgHWTBDNq/fz81DW/cuEHtQmodli5dmgFk2vXr17/44ou+ffv27NmTAehHTT2xkUeZLyQkRKFQUKqjskjIef7+/gxMgCyYKa9fv6Z2IbUOVSqV0FPq4+PDADLk+++/P336NDUE8+fPzwBSS9/UExt5Qubz9vZmYD5kwaxBFTGhp5RikXpKKR0yAJNRiTZu3DiKnAEDBjAANPWyEbJgFqO6PPWU/vnnn0JPac2aNRmAQT/99BPFzJIlS4oXL87AXqGpZy3IghZBe1XoKQ0NDW2rgYobpBcWFkajgLVr1x4xYgQDe4KmnnQgC1rWq1evhFMsHBwchHSIw7RAsHXr1k2bNtEo4AcffMAgp0NTT7KQBbPJzZs3hXRYoUIF6ilt0aIFA3sVGRk5fvx4KvioIcggJ0JTz4YgC2a3kydPUk/p4cOHhaZhtWrVGNiT3bt3f/PNN4sXL8ZXn5OgqWe7kAWtIzk5WWgaPnnyREiHxYoVY5Cj0Zc+btw4Hx+f6dOnM7BlaOrlJMiCVhYWFiakQw8PD+EUC3d3dwY5zsGDB6dNm7ZkyZL69eszsDVo6uVgyIJSERwcTLlw37591FFG6TAgIIBBTjFp0iT6O3/+fAa2AE09u4IsKDlHjx6ldEjDh0JPaeXKlRnYrBMnTlAv6Jw5c3A8lJSJTT1KePQXTT27giwoUfHx8UJPaXh4uNBTWrhwYQY2Zfbs2fT1US8o7k8pKWjqgTZkQal7/Pix0FPq6+tLuZAyorOzMwNpw32RJAVNPTAAWdBmXLp0iXIhZcR69epRLmzUqBEDSVq0aBGVtvQX90WyCjT1wCzIgrbn0KFDlAuptSH0lFaoUIGBlbRu3frPP/8Un16/fp2agIGBgbgvUnZCUw8yA1nQVkVHRws9pfRA6CnF7Xiy0+vXr/v160f91RcuXBCmCPdFWrx4cb58+RhYDJp6kLWQBW0e1XyFntJChQoJh5XiWIxssGDBgqCgIPr5eHh4rFu3DvdFshw09cCikAVzDuojFQ4rDQgIoBKZhg/TLFBNY/Xq1Qwyh4rj0aNHh4WFCU/lcvm2bdtwX6QsgaYeZDNkwRzowIEDlAuvXbsm9JSWLVtWmE4pkOO4hg0bLl26lEEmTJ48mXYy7Uxxyrlz5xhkCJp6YF3IgjnWmzdvhJ7SpKQkyoWbN28ODw9nmoZL06ZNcR2TDPvvv/+mT5/+6tUr7Ymenp6HDx9mYAyaeiA1yII53927dykXrl+/XiaTCVMcHR1btWolXtP50e2Y+BilTC7X9WqeoyB5/4TaPlqPKXQ43W/JM31z0sxKWSG9Ca/7NdpvmnoGr/6nc47mNbzpy7/fNO0Npaae8OPgNB9V3PYf/vcDld2a3cKrVDwn43mVepfm8s41YcIEvducbpJMllyiQs6/2SSaeiBxyIJ2oWPHjk+ePNGe4uLi0rlz5xJOXZ89SKTSWZWs+4XqRGd+ptOfuPTStzYDG2A2Xe9h1vp1bqSpaxBzqThBrl6bl4+896QSLKdQqVTiJafR1AObgIMJ7UJMTIz4mMop+hsbGxt9u/TzXIkNuuYuXiY3A2t4/TLu6PawtdNDBs4uyWxTmqbevXv3xITXoEEDNPVA+tAWtAs1a9Z0d3d3cHCgXj4vLy9fX19/x0BPT58eY2218M1JDm99/Px+/JD5NvBdoKkHOQ+yoL0IDg721aBiK+JF3JaFTwKnIQVKxZYFIWWqezbqkpdJjIGmHkb1IGdAj6i90L7Q2pk/Ipyds2q0DbKAh4/i4a0oxqycBQ009erXr9+/f3809SDnQRa0R/ExPCeXMZAMZxfHiKgElu0wqgeALGiPkhL5pAT0hEtIchKvtPw3gqYeQHrIggDWp31SZhZCUw/AKGRBe6Q+vw3DgpLC8elPOtyxY8fatWv379/PTIOmHkAGIAvaI/V53siCkpLu+5g+ffqRI0diY2MNvAhNPYDMQxa0S7z6ol8gIXzK1XYosU2dOvXu3bvs/SUOBGjqAVgCsiCAFLw7b3fnzp0//fTT06dPhYu+0t/169ejqQdgOciC9kgm5+g/A+ng1H3UM2fOPHr0aFRUlHjdc5q6YcOGCRMmoKkHYCHIgvZIpeTpPwPp0HwbJ06ciIyMpJ5Pudb9PZydnVu1asUAwDKQBQGsTzg45ocffjhz5syxY8eePHkSHh6emJjINPeJZABgMciCAFKgPnmlpEbv3r0jIiIuX7586NCha9euvXz5kgGAxSAL2iMZx2S4gJq08NrnzefOnbuJxDXWWgAAEABJREFUBgMAC0MWtEc8UqDUYJQWwEpQHNolnpl7Q63Q0JAJE0c2b1n7l83rgnZuDWhek2VCp4+abdy0hsF7PIdECGAdaAvaJ87ci8ccOrz/ytWLs2Ys9PMr9fp1eN8+gxhkHQ4pEMBKkAXtEa/iVSrzyt2YmOj8+QvWrduQHufPX6BcuQoMso7K/NY5AGQJZEEwbsq0sf/+e4weNAmoPmjgCGdnl5Wrlh766z+m6dvs/8mwt2/fbNi42sXFpUb1Op+NGO/j40uz7t27u2fvrxcung0Le1q8mF+bNp06duhq+ptGRUetW//DmdMnXr+JKFP6g2bNWrdt04mmT5oymv7On/uNsNiBA78vWDjzj73HXF1dZ82eSG3cOrUbLFoyRy6Xly1TfuaMr3ft3kHb5unp1bJFu2FDR9ECv+3avunnNQsXfDdl2pjw8FfFipUYN2bKmzev5y+YnqxMpo8wdsxkb+9cBj4C9Q8PHNyTtmHx0q9oyXp1G+349Zc9u44oFO9+UEFBW35YvfzAn//KTDwMiXIgsiCANSAL2iO5gqP/pi8/d87Sb5YvuHzlwrq12+kpjQuKsxwcHLZt20jpYddvhxITEoZ+2mf9hv+NGzuFZn2/cgklj7Fjp1Diefjw/vJvv86Xr0DtWvVMfNOFC2e9fPl89OhJxYqW2LV7+7Jv5lMeKl++koGXUBKijfTw8Nyx7U/KaoOGfDxqzOBGDQN+33P01u3rY8cNq1qleu3a9Wmbo6Oj1m/83+KFK31989I2z1swvURx/zU/bqVZlN62bd80dMjnBj4CLUZzN/68pkf3vhUqVMnjm5eGOY+fONKkcXNhS44eP1S/XmOZyUfiqjuocTEfAGtAFrRHymSe/rMsUqhQkT69B6gfuXtQQ+r27RvC9GnT5sfGxhTIX5AeU/rZv3/Pf2f/NT0LUj7r2SOwRvXa9HjI4JGNGjXz8jR+2czExERqjFKW8vLy9itRktp21FQVNoAabXdD71AWpKdJSUn9AocUKVKMHteqWW/nb1u//WZN7tw+9LRK5Wp37942/BGEUVXatm5dewtL0uPDhw8IWZDal1evXpr31TJmMk6m/g8A2Q9Z0B5RgZuF5wuWLl1OfEztMBpBfPeE53fu3Hrmv5OPHj0QJhQoUIiZrGLFKtt3/Ex9rZUrfVijRp0yWu9iAKVkoaFGXFxdfXL7irPcXN2oCSg+pZal8IC6UnPlyi2kQPWrXFyfvwgz5SOULpWySdQanjtv6tvIt16eXv8c/ZtycM2adZkZ0CMKYB3IgvaIVzFV1t1ZSefhpiqVauLkUUlJiYMHfValSnUPd4+RowYyc0z4cuaePb8ePnKAcqG7m3vnzj0C+w4WB970SdMJaaBPUnuzM/YRHJ2cxMfU/+nm5n706N8d2nc5dvxQi+Ztta8FahTPoz8UwDrQCwMWcfvOzZs3r306bEyD+k0of9AU7XaYKTw9PKmjde2P6r7K1q07bvp5LfVbpl9MqVIyyzDrI1B6bt2qw19/76PG65UrF1u1bM/MgmNEAawEWdAeyRScQmHZxgclA/qbxzev8PT+/VD6b8bLI9/u/G1bfHw8tdKoa3T4p2NoWI7SEs1ydHCksTpxSbGvMsuZ+xHatu0cHHyZWq6lS5X18yvJzMLxHFqDANaALGiPVMl8crJlmx406kbNo23bN0VGRT58eH/Fd4tqVK8d9vyZiS9XyBUbNq6eOXsC5ZWIiPCDB/+4E3KzYoUqNKtcuQrURAsNDaHH586fOXHyH2YZ5n6EwoWKVKlcLWjnlpYt2jFz4RhRACtBFrRHMhnHySxb6ObLl3/K5K+u37jasVPTyVPHDBo4okOHrjduBPfrb9Ipg25ubrNnLnr16gUNxXXp1nLr9o3Dho5u3+4jmtWpY/eApq2GDOvdJKD6n3/u7tNLfXgqb4H+xAx8hLp1GyqVyoAA828HqFIP1gJA9uN4DEfYn+1LH71+kdRrkh+DLDVpymgPD8/JE2czMx1Y/yT8WcLQBfhGALIbjhEFyKzo6GjqsL148ey14Ms/aS4sYDazL+wKAFkDWRCshlpOwVcv6ZzVpk2nT4eNZjbiwYPQseOG5cmTd9asRb6+eVgGqHCMKIB1IAvaI5ncvCuoWcj4sVMTkxJ1znJ1cWW2o3z5SkcOnWOZIJOrD9xlAJDtkAXtEa/MyiuoZZhw0W0gKqX6wF0GANkOWdAeobgFABAgCwJIAMdwwiCAVSAL2iO5NMYFIQV9GzI00QGsAFnQHql4XqVEmSsx+EIArAFZ0D7h9DSJwZkSAFaCLGiPeBWvUqHQlRBOhnoJgHUgC9ojTm7x64iCWahegmsZAlgFsqBdUqLMBQBQQxa0RzzDsRgAAGrIgvbIwZFzcEaPqITIFEqFA26tBGAFuL+gPXL1kuFMCUmJj+OdXB0YAGQ7ZEF71LBzroRYtDwkJPJVYokKzgwAsh2yoD1ycXfxLeywbfFdBhLw+4/3HJxYvfb5GABkO9xr3n4d2hIWciW6Qn2vSvUzdEs8yLTQa1EX/3qhcJD3mVycAYA1IAvatX3rHj28laBMYryS8QYPl6EwMXRWt8HZHK935Zz+g1UNvMqsbdA5WedE9Y8h9VQdm8czxpmyqWmXS/+OCpm6LyZ3QUWPMcUZAFgJsiCwxMTEty+VjJMbWCZNPpBxTPviM5zBMy+493/4dEtxvPqfjpdwmouKcca3Zczo0TNnzPDOlZvpuQYZrUp7hnrNvHpS+pWnWfLdO6Wemn4Z7Q2Sqbda9+dKnynlzsrcuV0YAFgVzpQA5ujomKcQs1HPwm/5FnLy9sYBlgCQEciCYNuSk5MVCoQxAGQQig+wbciCAJAZKD7AtiELAkBmoPgA26ZUKpEFASDDUHyADaOGoFwuZwAAGYUsCDYM3aEAkEkoQcCGJSUlOTjgHAkAyDhkQbBhaAsCQCahBAEbhiwIAJmEEgRsGLIgAGQSShCwYciCAJBJKEHAhuHoGADIJGRBsGFoCwJAJqEEARuGLAgAmYQSBGwYsiAAZBJKELBhGBcEgExCFgQbhrYgAGQSShCwYciCAJBJKEHAhiELAkAmoQQBG4YsCACZhBIEbBiyIABkEkoQsGHIggCQSShBwIZRCsyfPz8DAMgoZEGwYUlJSc+fP2cAABmFLAg2jNqC1CnKAAAyClkQbBiyIABkErIg2DBkQQDIJGRBsGHIggCQSciCYMOQBQEgk5AFwYYhCwJAJiELgg1DFgSATEIWBBuGLAgAmYQsCDYMWRAAMglZEGwYsiAAZBKyINgwZEEAyCRkQbBhyIIAkEnIgmDDkAUBIJOQBcGGIQsCQCYhC4INQxYEgExCFgQbhiwIAJnE8TzPAGzKkCFDHjx4QA8oBb5588bZ2VmpVCYmJl64cIEBAJhDxgBszYABA+Lj48PDw9++fctxXEJCAqXDAgUKMAAAMyELgu2pXbt21apVtadQW7BKlSoMAMBMyIJgk6g56O3tLT7Nnz//xx9/zAAAzIQsCDapUqVK1atXF0a1VSpVuXLlKlSowAAAzIQsCLZq4MCB1ASkB3ny5OnduzcDADAfsiDYqlKlStWoUYNGBEuXLl2tWjUGAGA+nCkBGffX5if3g+OTEnml8t0UnvEc44THnPrpu6nvpzEKN44TV5AyI/V0rdemn6V5j1S01q/jqc6X6FoszRsZeTljcgWTyZlvQUXXz4szALBNyIKQQQc2hT24Hu1fxbNERTeZwiH9Ahyv/sc0qUWl/sOz1BmF0zxSL5M67Ymv5d6nKvWs90lLXDLlQZospU7EvPYqaU0qdXJOeQfNG2u9SrO49jaIj2nzZfy7jUxDxbMnt97euvDWQS7rN82PAYANQhaEjNi88H5sdHKPcSUZMPbHT/ejXikHz/VnAGBrMC4IZrt37c2bl0iBKdoOKE71yQMbnzAAsDW4jiiY7fzht26ecgZa8hRxeRqawADA1qAtCGaLj+KdXJEFU/HM5ZCYgMEFANuDtiCYLTEeg8lpKZVcciIDAJuDLAgAAPYLWRAAAOwXsiBAFuAYANgkZEGALICBUgAbhSwIZuNk9B+Nn1RkMt1XXwMAiUMWBLPxKvqPxk8qOGoWwEYhCwJkAcqCSIQAtghZEAAA7BeyIAAA2C9kQTCbXM7kODomNRknk+OicgA2CFkQzKZUMhmOjklNxavEWw0DgA1BFgQAAPuFe0pATvbmzesmAdWP/PMXAwDQBW1BgCyAU+YBbBSyIJiPw2Uz08LJggA2ClkQzMdn02UzIyLCV65aGnztcnx8fI0adQL7DCpSpBhNv3fv7oBBPVZ+v2Hz5nUnTv6TJ0/eJo1bDBk8Uq45TPPQ4QPr1q2KjIqsW7dhj259WbaQcWgNAtgkjAuCRCmVyjHjhl66fH7M6Mk/rdmWyzv38BH9njx9TLMcHBzo75KlXwUEtDq4/9SUSV9t3/GzMPgXGhoyd97UFi3a/bxpV8sW7VZ8t4hlCxWP1iCATUIWhAzIjsbg1auXHj68P3nSnFo16+bO7fPpsNGeXt5BQZvFBRo1bNa4UTPKiJUrf1iwQKHbt2/QxN17duTLmz+w7yBPD8+qVaq3bduZAQDohx5RyIDsGBi8GnyJMtyHVWu8e0uOq1K52uUrF8QFSpcuJz52d/eIjo6iB0+ePCpewl+cXrZseZY9MFYKYJuQBcFsMgUns/y1YyirJSUlNQmorj3R2ztXymbIdPRkREa+LVy4qPjUxdmFZQ8etxgEsEnIgmA2VTKvUli8zPfx8XVxcZn71TLtiXKZkcuUeXp6xSfEi09jY2NYtqCmKofhBQAbhCwIEuXvXzouLi5v3vyFChYWpjx99sTbK5fhV+XLV+DfU8dUKpXQUjx1+jjLFjxRMQCwOai+gkRV+7BmzZp1Fy+e8/x52Nu3b3bt3jHs07779+8x/KrGjZu/efN6xXeLKCtdvHRu167tDABAP7QFQbrmz/1mz96g2V9Nun79apEixZo1a/3RRz0Nv6RG9drDho7as+fXps1q5MuXf8qkrz4fPQhnMQCAPhwKCDDXupn3HJ0UHYYXYfDemX0vb52LHLHEnwGATUFbEMxGA2AqVJ5S49QXj8E+AbA9yIJgWSqVqmOnpjpnJSYmOjg46Lz0WLHift99+xPLOpOmjA6+eknnrITEBCdHp/TTHZ2cgnYcYKZRqS8egzMGAWwPsiBYlkwm27x5r85ZCQkJTk5OOmdl+Tno06bMU6p03wY3IT7eydmZWX4bAECCkAXBbDK5uv/P9OU93D3Mmm4Jrq6u+mZl52YAgNQgC4LZVEoe44JpUK0AN5UAsEXIggBZgMOgIIBtQhYEyAIqhnOOAGwSsiAAANgvZEEwGydjMvT/pYb9AWCjkAXBbJqz5hkAQA6ALAiQBVArALBRyIIAAGC/kAXBbAoFJ1NgICwVmYyTyxkA2BzcXxDM5ujClMpkBloS4hNkDugWBbA9yLJvx1YAAAEXSURBVIJgtmLl3eLe4sbqqbx4mJQ7nxMDAFuDLAhmq9Mmj1zOH9nxmIFGxMu42Mjkrp/jhosAtgd32YUM+nFyiHtuWbvBfsy+nfrjecjFqMCpRd29HBkA2BpkQci49bPvxUYqZQqmTEp7sAzHMVMiixPOMaBF9VyL2uh6ZFyqkxfTLM9pncPApT6fQViSe//e6WfpXKE2hZMsOVHp6MR6flnUAykQwDYhC0KmRL+Ou3YqJiHOpCjS5Bs+7TRNEIr32tU85M1ZCZ/6yi2pM1qqmVz68/p4xnOM4zN08Re5IytS1qloKU8GADYLWRAAAOwXzhcEAAD7hSwIAAD2C1kQAADsF7IgAADYL2RBAACwX8iCAABgv/4PAAD//7VYbt4AAAAGSURBVAMAuqgimqSu9TIAAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001AD746B2980>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay2 = \"\"\"India and AI Time\n",
    "\n",
    "Now world change very fast because new tech call Artificial Intel… something (AI). India also want become big in this AI thing. If work hard, India can go top. But if no careful, India go back.\n",
    "\n",
    "India have many good. We have smart student, many engine-ear, and good IT peoples. Big company like TCS, Infosys, Wipro already use AI. Government also do program “AI for All”. It want AI in farm, doctor place, school and transport.\n",
    "\n",
    "In farm, AI help farmer know when to put seed, when rain come, how stop bug. In health, AI help doctor see sick early. In school, AI help student learn good. Government office use AI to find bad people and work fast.\n",
    "\n",
    "But problem come also. First is many villager no have phone or internet. So AI not help them. Second, many people lose job because AI and machine do work. Poor people get more bad.\n",
    "\n",
    "One more big problem is privacy. AI need big big data. Who take care? India still make data rule. If no strong rule, AI do bad.\n",
    "\n",
    "India must all people together – govern, school, company and normal people. We teach AI and make sure AI not bad. Also talk to other country and learn from them.\n",
    "\n",
    "If India use AI good way, we become strong, help poor and make better life. But if only rich use AI, and poor no get, then big bad thing happen.\n",
    "\n",
    "So, in short, AI time in India have many hope and many danger. We must go right road. AI must help all people, not only some. Then India grow big and world say \"good job India\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 36.80686588s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 34.622287121s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 30.478206442s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 29.911763967s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 27.763382788s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 23.631046896s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 22.350675689s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 15.507743385s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 12.297359294s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 12\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 10.138607306s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 6.215248816s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 5.922478553s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 59.360157408s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 57.744575826s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 41.59975909s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 22.064489321s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 22\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m intial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124messay\u001b[39m\u001b[38;5;124m'\u001b[39m: essay2\n\u001b[0;32m      3\u001b[0m }\n\u001b[1;32m----> 5\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3050\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3047\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3048\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3050\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3051\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3052\u001b[0m     config,\n\u001b[0;32m   3053\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3054\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3056\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3057\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3058\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3059\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3060\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3061\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3062\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3063\u001b[0m ):\n\u001b[0;32m   3064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3065\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2633\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2632\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2634\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2635\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2636\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2637\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2638\u001b[0m ):\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2641\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2643\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:258\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tb \u001b[38;5;241m:=\u001b[39m exc\u001b[38;5;241m.\u001b[39m__traceback__:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:520\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 interrupts\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    519\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[1;32m--> 520\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_executor.py:80\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m, in \u001b[0;36mclarity_feedback\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclarity_feedback\u001b[39m(state : EvaluateEssay) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProvide clarity feedback on the following essay, focusing on grammar, punctuation, and readability.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEssay: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43messay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclarity_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m: output}\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1962\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1959\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1960\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 1962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:382\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    376\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    377\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    380\u001b[0m         cast(\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 382\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    383\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    384\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    385\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    386\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    387\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    388\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    389\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    390\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    391\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    392\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    393\u001b[0m     )\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1101\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1099\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1100\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:911\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    910\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 911\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    912\u001b[0m                 m,\n\u001b[0;32m    913\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    914\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    915\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    916\u001b[0m             )\n\u001b[0;32m    917\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    919\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1205\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1205\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1206\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1207\u001b[0m     )\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:2099\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   2098\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries\n\u001b[1;32m-> 2099\u001b[0m response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m   2100\u001b[0m     request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2102\u001b[0m     generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m   2103\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m   2104\u001b[0m )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:232\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    225\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    226\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (request \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:202\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mmessage:\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:869\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    210\u001b[0m         error_list,\n\u001b[0;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    212\u001b[0m         original_timeout,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\02_ Kaustubh\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 22.064489321s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 22\n}\n]"
     ]
    }
   ],
   "source": [
    "intial_state = {\n",
    "    'essay': essay2\n",
    "}\n",
    "\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
